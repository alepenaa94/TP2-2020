{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/alepenaa94/TP1_Real_or_Not/blob/master/TP1_Real_or_Not.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iwY7zLPkMCLI"
   },
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook la idea es realizar todo el procesamiento del set de datos, limpieza en los campos de ser necesario y sección para la generacion de los features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ideas de cosas a realizar\n",
    "\n",
    "--> Generar un N-grama <br>\n",
    "--> mejorar los stopwords <br>\n",
    "--> poder darle mas caracter a un tweet segun su texto <br>\n",
    "--> TF-IDF <br>\n",
    "--> Embeddings <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "0R_dMyhfL8QX",
    "outputId": "5d011d54-140f-4716-cdd7-7b31c412e540"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KiQERldrjl68"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../Data/train.csv', encoding='latin-1',dtype={'id': np.uint16,'target': np.bool})\n",
    "test_df = pd.read_csv('../Data/test.csv', encoding='latin-1',dtype={'id': np.uint16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "sTfW9uPBjl10",
    "outputId": "237774d0-8fb8-49be-a7a2-ab000ed1c736",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0    True  \n",
       "1    True  \n",
       "2    True  \n",
       "3    True  \n",
       "4    True  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza de la información"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En base a lo aprendido en el TP1, limpiamos la información de algunos campos del dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['keyword'] = train_df['keyword'].str.replace('%20',' ')\n",
    "test_df['keyword'] = test_df['keyword'].str.replace('%20',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['keyword'].fillna('None',inplace=True)\n",
    "test_df['keyword'].fillna('None',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['location'].fillna('Unknown',inplace=True)\n",
    "test_df['location'].fillna('Unknown',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volvemos a generar las columnas utilizadas para el TP1 ya que podrían resultar features útiles para el modelo de predicción."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Cantidad de palabras en el tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['cantidad_de_palabras'] = train_df['text'].str.count(' ') + 1\n",
    "test_df['cantidad_de_palabras'] = test_df['text'].str.count(' ') + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Longitud del tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['longitud_del_tweet'] = train_df['text'].str.len()\n",
    "test_df['longitud_del_tweet'] = test_df['text'].str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Cuartiles de longitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>longitud_del_tweet</td>\n",
       "      <td>7613.0</td>\n",
       "      <td>101.460397</td>\n",
       "      <td>34.063901</td>\n",
       "      <td>7.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>163.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     count        mean        std  min   25%    50%    75%  \\\n",
       "longitud_del_tweet  7613.0  101.460397  34.063901  7.0  78.0  107.0  134.0   \n",
       "\n",
       "                      max  \n",
       "longitud_del_tweet  163.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['longitud_del_tweet'].describe().to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>longitud_del_tweet</td>\n",
       "      <td>3263.0</td>\n",
       "      <td>102.562059</td>\n",
       "      <td>34.314676</td>\n",
       "      <td>5.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>169.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     count        mean        std  min   25%    50%    75%  \\\n",
       "longitud_del_tweet  3263.0  102.562059  34.314676  5.0  79.0  110.0  134.0   \n",
       "\n",
       "                      max  \n",
       "longitud_del_tweet  169.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['longitud_del_tweet'].describe().to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[train_df['longitud_del_tweet'] < 78.0,'longitud_categ'] = \"0 a 25\"\n",
    "train_df.loc[train_df['longitud_del_tweet'] >= 78.0,'longitud_categ'] = \"25 a 50\"\n",
    "train_df.loc[train_df['longitud_del_tweet'] >= 107.0,'longitud_categ'] = \"50 a 75\"\n",
    "train_df.loc[train_df['longitud_del_tweet'] >= 134.0,'longitud_categ'] = \"75 a 100\"\n",
    "\n",
    "test_df.loc[test_df['longitud_del_tweet'] < 79.0,'longitud_categ'] = \"0 a 25\"\n",
    "test_df.loc[test_df['longitud_del_tweet'] >= 79.0,'longitud_categ'] = \"25 a 50\"\n",
    "test_df.loc[test_df['longitud_del_tweet'] >= 110.0,'longitud_categ'] = \"50 a 75\"\n",
    "test_df.loc[test_df['longitud_del_tweet'] >= 134.0,'longitud_categ'] = \"75 a 100\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos el método de Smothing. (El código está basado en el obtenido de la siguiente fuente: https://gist.github.com/marnixkoops/e68815d30474786e2b293682ed7cdb01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothing(df, column, target, weight=100):\n",
    "    mean = df[target].mean()\n",
    "    agg = df.groupby(column)[target].agg(['count', 'mean'])\n",
    "\n",
    "    dic = {}\n",
    "    \n",
    "    for i in df[column].unique():\n",
    "        dic[i] = (agg.loc[i]['count'] * agg.loc[i]['mean'] + weight * mean) / (agg.loc[i]['count'] + weight)\n",
    "        \n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_categ_encoding_dic = smoothing(train_df,'longitud_categ','target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['longitud_categ'] = train_df['longitud_categ'].map(long_categ_encoding_dic)\n",
    "test_df['longitud_categ'] = test_df['longitud_categ'].map(long_categ_encoding_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Realiza menciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['tiene_menciones'] = train_df['text'].str.contains('@')\n",
    "test_df['tiene_menciones'] = test_df['text'].str.contains('@')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Tweet expresivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['es_expresivo'] = (train_df['text'].str.contains('\\!\\!') | train_df['text'].str.contains('\\?\\?'))\n",
    "test_df['es_expresivo'] = (test_df['text'].str.contains('\\!\\!') | test_df['text'].str.contains('\\?\\?'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Cantidad de hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['cantidad_de_hashtags'] = train_df['text'].str.count('#')\n",
    "test_df['cantidad_de_hashtags'] = test_df['text'].str.count('#')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Tiene links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['tiene_links'] = train_df['text'].str.contains('http')\n",
    "test_df['tiene_links'] = test_df['text'].str.contains('http')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Ubicaciones con tweet único"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_location_unico(location):\n",
    "    ubicaciones_unicas = train_df['location'].value_counts()[train_df['location'].value_counts() == 1].index\n",
    "    return (location in ubicaciones_unicas)\n",
    "\n",
    "def test_location_unico(location):\n",
    "    ubicaciones_unicas = test_df['location'].value_counts()[test_df['location'].value_counts() == 1].index\n",
    "    return (location in ubicaciones_unicas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['location_unico'] = train_df['location'].map(train_location_unico)\n",
    "test_df['location_unico'] = test_df['location'].map(test_location_unico)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Encoding del campo keyword"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como la columna keyword es de tipo categórico, vamos a buscar una forma de codificarla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_encoding_dic = smoothing(train_df,'keyword','target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['keyword_encoded'] = train_df['keyword'].map(keywords_encoding_dic)\n",
    "test_df['keyword_encoded'] = test_df['keyword'].map(keywords_encoding_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\FF633NG\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\FF633NG\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\FF633NG\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from textblob import TextBlob\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "df=train_df.copy()\n",
    "\n",
    "#vamos a limpiar un poco el tweet\n",
    "pattern_exclude = '(one|dont|cant|would|im|people|go|make|time|love|amp|get|house|update|talk'+\\\n",
    "                  '|want|today|know|say|us|day|crush|see|back|think|look|rigth|remember|car|shes'+\\\n",
    "                  '|thing|let|still|lol|much|thank|take|way|youre|road|another|really|save|hows'+\\\n",
    "                  '|play|even|theres|everyone|feel|year|work|check|two|great|ing|like|sink|href|hr|hs'+\\\n",
    "                  '|every|build|youtuve|video|n|home|body|bag|photo|stay|game|start|gt|fuck|help'+\\\n",
    "                  '|best|well|california|end|live|e|rt|wreck|plan|full|may|ies|u|could|many|last'+\\\n",
    "                  '|find|service|leave|collapse|world|war|destroy|wound|break|right|hear|school)+'\n",
    "\n",
    "def filter_words(tweet):\n",
    "    tweet = re.sub(r'(\\b[\\w]+:\\/\\/[\\w -\\?&;#~=\\.\\/@]+[\\w\\/])', ' ', tweet)\n",
    "    tweet = re.sub(r'\\'', '', tweet)\n",
    "    return re.sub(r'[www.]*[A-z]+.(com|gov|edu|net|mil|org|io|int)+', ' ', tweet)\n",
    "\n",
    "def text_to_blob(tweet):\n",
    "    tweet_blob = TextBlob(str(tweet))\n",
    "    return ' '.join(tweet_blob.words)\n",
    "\n",
    "\n",
    "def normalization(tweet_list):\n",
    "        lem = WordNetLemmatizer()\n",
    "        normalized_tweet = []\n",
    "        for word in tweet_list:\n",
    "            word_aux = word.lower().strip()\n",
    "            if re.match(pattern_exclude,\n",
    "                        word_aux):\n",
    "                continue\n",
    "            normalized_text = lem.lemmatize(word_aux,'v')\n",
    "            normalized_tweet.append(normalized_text)\n",
    "        return normalized_tweet\n",
    "\n",
    "def clean(tweet):\n",
    "    tweet_list = [word for word in (text_to_blob(filter_words(tweet))).split()]\n",
    "    clean_tokens = [tkn for tkn in tweet_list if re.match(r'[A-z]+', tkn)]\n",
    "    clean_s = ' '.join(clean_tokens)\n",
    "    l_aux = normalization(clean_s.split())\n",
    "    return ' '.join([word for word in l_aux if word not in stopwords.words('english')])\n",
    "\n",
    "train_df['clean_text'] = train_df['text'].apply(clean)\n",
    "test_df['clean_text'] = test_df['text'].apply(clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "docs=train_df['clean_text'].to_list()\n",
    "\n",
    "#cv=CountVectorizer(strip_accents='ascii')\n",
    "cv=CountVectorizer(max_features=500,min_df=0.01,max_df=0.40)\n",
    "word_count_vector=cv.fit_transform(docs)\n",
    "\n",
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "tfidf_transformer.fit(word_count_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idf_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>fire</td>\n",
       "      <td>4.153919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>bomb</td>\n",
       "      <td>4.526098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>burn</td>\n",
       "      <td>4.772958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kill</td>\n",
       "      <td>4.881498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>flood</td>\n",
       "      <td>4.887888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>attack</td>\n",
       "      <td>4.988984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>crash</td>\n",
       "      <td>4.996102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>disaster</td>\n",
       "      <td>5.032469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>police</td>\n",
       "      <td>5.093557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>storm</td>\n",
       "      <td>5.109430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>train</td>\n",
       "      <td>5.175570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>watch</td>\n",
       "      <td>5.184154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>scream</td>\n",
       "      <td>5.210356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>suicide</td>\n",
       "      <td>5.219245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>man</td>\n",
       "      <td>5.264915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>first</td>\n",
       "      <td>5.293353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cause</td>\n",
       "      <td>5.303015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>drown</td>\n",
       "      <td>5.342624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dead</td>\n",
       "      <td>5.383867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hiroshima</td>\n",
       "      <td>5.471836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>accident</td>\n",
       "      <td>5.483397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>life</td>\n",
       "      <td>5.495093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>fear</td>\n",
       "      <td>5.531025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>die</td>\n",
       "      <td>5.555717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>blow</td>\n",
       "      <td>5.555717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>survive</td>\n",
       "      <td>5.555717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rescue</td>\n",
       "      <td>5.581035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           idf_weights\n",
       "fire          4.153919\n",
       "bomb          4.526098\n",
       "burn          4.772958\n",
       "kill          4.881498\n",
       "flood         4.887888\n",
       "attack        4.988984\n",
       "crash         4.996102\n",
       "disaster      5.032469\n",
       "police        5.093557\n",
       "storm         5.109430\n",
       "train         5.175570\n",
       "watch         5.184154\n",
       "scream        5.210356\n",
       "suicide       5.219245\n",
       "man           5.264915\n",
       "first         5.293353\n",
       "cause         5.303015\n",
       "drown         5.342624\n",
       "dead          5.383867\n",
       "hiroshima     5.471836\n",
       "accident      5.483397\n",
       "life          5.495093\n",
       "fear          5.531025\n",
       "die           5.555717\n",
       "blow          5.555717\n",
       "survive       5.555717\n",
       "rescue        5.581035"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_idf = pd.DataFrame(tfidf_transformer.idf_, index=cv.get_feature_names(),columns=[\"idf_weights\"])\n",
    "df_idf.sort_values(by=['idf_weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf_(doc):\n",
    "    tf_idf_vector=tfidf_transformer.transform(cv.transform([doc]))\n",
    "    return (pd.Series(tf_idf_vector.toarray()[0]).sum())\n",
    "\n",
    "train_df['tfidf_score']=train_df['clean_text'].apply(tf_idf_)\n",
    "test_df['tfidf_score']=test_df['clean_text'].apply(tf_idf_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_df['clean_text']\n",
    "del test_df['clean_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.set_index('id').iloc[:,3:]\n",
    "test_df = test_df.set_index('id').iloc[:,3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos los dataframes de train y test en archivos .csv para usarlos en el Notebook de Algoritmos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('../Data/train_features.csv')\n",
    "test_df.to_csv('../Data/test_features.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Copia de Copia de TP1_Real_or_Not.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
